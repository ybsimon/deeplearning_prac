{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from functools import partial\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 150  # codings\n",
    "n_hidden3 = n_hidden1\n",
    "n_outputs = n_inputs\n",
    "\n",
    "learning_rate = 0.01\n",
    "l2_reg = 0.0001\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer() # He initialization\n",
    "l2_regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
    "my_dense_layer = partial(tf.layers.dense,\n",
    "                         activation=tf.nn.elu,\n",
    "                         kernel_initializer=he_init,\n",
    "                         kernel_regularizer=l2_regularizer)\n",
    "\n",
    "hidden1 = my_dense_layer(X, n_hidden1)\n",
    "hidden2 = my_dense_layer(hidden1, n_hidden2)\n",
    "hidden3 = my_dense_layer(hidden2, n_hidden3)\n",
    "outputs = my_dense_layer(hidden3, n_outputs, activation=None)\n",
    "\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))\n",
    "\n",
    "reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "loss = tf.add_n([reconstruction_loss] + reg_losses)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "0 Train MSE: 0.0251017\n",
      "1 Train MSE: 0.0125263\n",
      "2 Train MSE: 0.0103401\n",
      "3 Train MSE: 0.0100263\n",
      "4 Train MSE: 0.0101155\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "n_epochs = 5\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        n_batches = mnist.train.num_examples // batch_size\n",
    "        for iteration in range(n_batches):\n",
    "            print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\") \n",
    "            sys.stdout.flush()                                         \n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch})\n",
    "        loss_train = reconstruction_loss.eval(feed_dict={X: X_batch})   \n",
    "        print(\"\\r{}\".format(epoch), \"Train MSE:\", loss_train)           \n",
    "        saver.save(sess, \"./my_model_all_layers.ckpt\")                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"autoencoders\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)\n",
    "\n",
    "def plot_image(image, shape=[28, 28]):\n",
    "    plt.imshow(image.reshape(shape), cmap=\"Greys\", interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "def show_reconstructed_digits(X, outputs, model_path = None, n_test_digits = 2):\n",
    "    with tf.Session() as sess:\n",
    "        if model_path:\n",
    "            saver.restore(sess, model_path)\n",
    "        X_test = mnist.test.images[:n_test_digits]\n",
    "        outputs_val = outputs.eval(feed_dict={X: X_test})\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 3 * n_test_digits))\n",
    "    for digit_index in range(n_test_digits):\n",
    "        plt.subplot(n_test_digits, 2, digit_index * 2 + 1)\n",
    "        plot_image(X_test[digit_index])\n",
    "        plt.subplot(n_test_digits, 2, digit_index * 2 + 2)\n",
    "        plot_image(outputs_val[digit_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_all_layers.ckpt\n",
      "Saving figure reconstruction_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAGoCAYAAACXNJbuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHPNJREFUeJzt3VuMnVX5P/BV2s50ZnqiMuVQoK0caiEQDgE5hkoImphg\n1JCIxGjQRGKiiSRqIDFRb/ROuVE0GhDwQiURIwFBSVAgRQiniCAUCqK0lCmlLdDOqe3v1v8/61n2\n3TOdedp+PpfP273Wu/ee7m/e5Flrzdm3b18BAGbXEbN9AwCAQAaAFAQyACQgkAEgAYEMAAkIZABI\nQCADQAICGQASEMgAkMC8WZrX9mAc7ObM9g0cLkZGRvxedDBnTv1P066Ms2d4eHi/fi88IQNAAgIZ\nABIQyACQgEAGgARmq6kLgCmImrciRxxRf/5qNXvNZoPY4diE5gkZABIQyACQgEAGgAQEMgAkIJAB\nIAGBDAAJWPYEMI1ay5FmYilPtLwpuq/o35dSyt69e6v1iYmJTnP0YrY/x9ngCRkAEhDIAJCAQAaA\nBAQyACQgkAEgAV3WAA3T2Tkc2bNnT+e5W93RXcaKOqZLKWVycrJaj7qvW/c0d+7caRvrUHX4vWMA\nSEggA0ACAhkAEhDIAJCAQAaABHRZA4e9XrqZo/2UW/ssRx3FUQdyS19fX7U+b179Zz26r6iTupT4\nc4m6wvv7+8OxovuKRHO0RJ9j6ztpdZnPNE/IAJCAQAaABAQyACQgkAEgAYEMAAkIZABIwLIn4LAR\nLeNpLYvpuvwmWtpUSvfDGqKlTS3R/UZztJYjjY6OVuvRUqHx8fFwrGieqN763KPvsesyrVK6H2LR\n+ltpXdsfnpABIAGBDAAJCGQASEAgA0ACAhkAEtBlDRxyunZTtzpto47iqD42NhaOFXUtR69ZtGhR\nOFbU0Ry9l2XLllXrrQMhovm7douXEnc6RwdCtDrMo7F6+X6jsVoHjkR0WQPAIUAgA0ACAhkAEhDI\nAJCAQAaABHRZ/5fHHnusWr/55pvD16xYsaJaHxgYqNY///nPh2NFXZBRHaiLul2jjtqoa7iUUnbt\n2lWtb926tVrfvHlzONbrr79erUfd19HvSClxB/TQ0FC1Pjw8XK0vXbo0nGPBggXVevQ5Rp3nLV27\nr0uJ30vUmT1//vxpu69euq/3lydkAEhAIANAAgIZABIQyACQgEAGgAQEMgAkMGeqm2H3aFYm/V/W\nrFlTrW/YsGFG5l+yZEm1fsEFF8zI/AfaqlWrwms33nhjtX7iiSceoLuZsgO39oH/x8jIyLT9XkQH\nMrQOhIiWMb388svV+iuvvBKO9a9//avT/K3lOtGynO3bt1fr0ZKgaGlTKaVs27YtvFazePHi8Fr0\n/z9a8vWBD3wgHOvyyy+v1k8++eRqfeHCheFYUQb2soQrWhJ11FFH7dfvhSdkAEhAIANAAgIZABIQ\nyACQgEAGgAQcLvFf7r777mr9mWeeCV9z+umnV+v/+Mc/qvW//e1v4Vi///3vq/X777+/Wl+9enW1\n/uqrr4ZzdDVvXvwncuyxx1br//73vzvPE3Vgfutb3+o8FnQ9AGDv3r3hteiQg6gDurVyZfny5dV6\ntMLi/fffD8d6++23O70m6rKOximllL///e/V+hFH1J/lPvzhD4djvfHGG9X6448/Xq2vXLkyHCta\nfREd9tM6QCM6WCR6j63vd6qrljwhA0ACAhkAEhDIAJCAQAaABAQyACSgy/q/rF27tlO95cwzz6zW\nr7nmmvA1P/jBD6r11157rVqPuqw3btzYvrkOos7MUuIu6+i+RkZGwrE+9KEPdbsxDntdO6lLKWVg\nYKDzWFFndLQCYdmyZZ3vK+qy3rVrV/iaLVu2VOvR/9loP+dWJ/emTZuq9Wif6eizKqWUBx98sFr/\ny1/+Uq23vpPBwcFqPfp+W3uVR6K9wnv5u9tfnpABIAGBDAAJCGQASEAgA0ACAhkAEhDIAJCAZU+J\nLFiwoFrvuiSol2VavYgOyti6dWu13tp4/sorr5yWe4JSui9Nif7vlRIvb+rv76/Wo4MP/tc8Nb0s\n14mWPUWHJYyOjoZjRQdoRO9j+/bt4VjR70U0x5FHHhmOFR1GMzQ0VK23/h6ig0UO5PKmiCdkAEhA\nIANAAgIZABIQyACQgEAGgAR0WdPU2nj+k5/8ZLUedS3+6Ec/CseKNoWHyL59+8JrXTtkW/8+6qaO\n6lHXcCnxPY+Pj3f696XE3dTRoQiR1nvv2mXdOkDmueeeq9ajgyouvvjicKzjjjsuvFbT9TNpaX1e\nre9rf3hCBoAEBDIAJCCQASABgQwACQhkAEhAlzVNt912W3jtzTffrNajrsmVK1dOxy3B/xR1wkZd\nsL10bM+dO7daj1YZlFLKxMREtb579+5Oc5cS70EddRRH99W63+hz2bJlS7V+++23h2NFXdbnn39+\ntX7RRReFYy1evDi8VjOdHflT7aRu8YQMAAkIZABIQCADQAICGQASEMgAkIAua0oppbzyyivV+g03\n3NB5rPXr11frxxxzTOexoBdRp3HUGd3a6zh6TWRycjK8tmvXrk5jtfbF7vpeog7vaF/qUuIO5Mcf\nf7xaf+ihhzqPdemll1brrVUZ0ecS7Ql+sPCEDAAJCGQASEAgA0ACAhkAEhDIAJCAQAaABCx7opRS\nyh/+8IdqPVoqUUopV199dbX+wQ9+cFruCaZbdJBC64CB1pKomtbSpuhggsHBwWp93rz4J7rrARrR\n8qaBgYFwjnfeeadaf/rpp6v1HTt2hGOtW7euWj/zzDOr9egzaYk+k9Z3eMQReZ5L89wJABzGBDIA\nJCCQASABgQwACQhkAEhAl/VhJuqa/t3vflet9/f3h2N9//vfr9a7bsYPMyXqQG6JunBbh0h0HSs6\nLKG1yuG9997rdF+9dHK/8MIL1frGjRur9VWrVoVjfeQjH6nWjzvuuGq91RkdfS7Rb0/rdyz6vLp2\nsU8HT8gAkIBABoAEBDIAJCCQASABgQwACeiyPsz84he/qNYffvjhav2zn/1sOJY9qznYRB2yrc7Z\nqNs36pheuHBhOFb0mmiP7e3bt4djjY2NVetRx3a0l/XmzZvDOR544IFq/T//+U+1fu6554ZjnX/+\n+dV6X19ftd7aYzrqjI6+q9bKj17+Jg4UT8gAkIBABoAEBDIAJCCQASABgQwACQhkAEjAsqdD0DPP\nPBNe++pXv1qtL126tFr/3ve+Ny33BDOp65KV1kEGkWgpTeuwhmi5TnS/0QEHpZSybNmyan3RokXV\nenQgw/r168M5HnvssWp9YGCgWr/wwgvDsYaGhqr16HOczqVovSxhcrgEABymBDIAJCCQASABgQwA\nCQhkAEhAl/VBbPfu3dX6NddcE74m6k689tprq3UHSHAoiQ5xaHXORoc1RKJu5lJKGR8f7zTW4OBg\neC3qpo66lp988slq/f777w/neO2116r1z3zmM9X66aefHo4V3Vf0m9T6HKNu9f7+/mq9dVBFNH/U\nZd3qfJ9qB7YnZABIQCADQAICGQASEMgAkIBABoAEdFkfBKLO0I9//OPV+osvvhiOtXbt2mr9u9/9\nbvcbg6RanbA1rb2s+/r6qvWoc3fXrl3hWK1rNUceeWR4LfpdePXVV6v1u+++u1p/9NFHwznOO++8\nav2jH/1otT48PByOFXVZR53nrS7rrt3U9rIGAPabQAaABAQyACQgkAEgAYEMAAkIZABIwLKng8C2\nbduq9YceeqjzWHfccUe1vmzZss5jwaEiWpJTSry8KNJaFhMty5k3r/5T3Bpr586d1frDDz9crd9z\nzz3V+rHHHhvO8bnPfa5aP/vss8PXREZHR6v1rp9JKfGSpOh7bH2H0WsO5PKmiCdkAEhAIANAAgIZ\nABIQyACQgEAGgAR0WSeyY8eOav2CCy7oNM6dd94ZXuulOxIONl27cFuibttexoo6igcGBqr1Vnfw\nyMhItf7EE09U69EhDldccUU4R/TbMzg4WK3v3r07HCv6HKPPpPX5Rt9vdEhI63PsehCJwyUA4BAn\nkAEgAYEMAAkIZABIQCADQAK6rBO59dZbq/WNGzd2GueSSy4Jr3XtKISDUdQJG/39R52+rddMTExU\n663u4P7+/k6v2b59ezjWvffeW63fd9991Xr0Hk899dRwjr6+vmo96tiO6q2xovtqdTNH3dSt7zEy\nG3tWRzwhA0ACAhkAEhDIAJCAQAaABAQyACQgkAEgAcueZtiGDRvCa9/5zndm7kbgMNR1OVQp8cEE\n0znW1q1bq/XooIhSSrnnnnuq9c2bN1fr69atq9aXLl0azjE2NlatR8uL5s+fH47VdXnT5ORkOFbX\n5Zutf9/1e3S4BAAc4gQyACQgkAEgAYEMAAkIZABIQJf1DHv44YfDazt37uw01tq1a6v1gYGBTuMA\nsag7OOrCbR0uEXVZR93J0b8vpZTTTjutWl+9enW1fsYZZ1TrK1asCOdodU3XtDqjo88lOiii9d67\ndmz3cqjObBw64QkZABIQyACQgEAGgAQEMgAkIJABIAFd1geBiy66qFr/05/+VK3rsuZw0Mv+xNMp\n6gKO9n8uJe40jrqGjz/++HCsK664otMcw8PD1frQ0FA4x/j4eLXeS2d0JPoeo8+kF7PRMd0LT8gA\nkIBABoAEBDIAJCCQASABgQwACQhkAEhgziy1gx8cPegQ675bPT0ZGRk55H8vouVCExMT4Wui3+55\n8+qrWaPlRa0M6HqwRmspWtfX9LKEKqvh4eH9+r3whAwACQhkAEhAIANAAgIZABIQyACQwGx1WQMA\n/8UTMgAkIJABIAGBDAAJCGQASEAgA0ACAhkAEhDIAJCAQAaABAQyACQgkAEgAYEMAAkIZABIQCAD\nQAICGQASEMgAkIBABoAEBDIAJCCQASABgQwACQhkAEhAIANAAgIZABIQyACQgEAGgAQEMgAkIJAB\nIAGBDAAJCGQASEAgA0ACAhkAEhDIAJCAQAaABAQyACQgkAEggXmzNO++WZoXpsuc2b6Bw8XIyIjf\nCw5qw8PD+/V74QkZABIQyACQgEAGgAQEMgAkMFtNXQD8D3PmxL1A+/bVe92i13St9yK6p9a11msO\nN56QASABgQwACQhkAEhAIANAAgIZABIQyACQgGVPALMsWvqzZ8+e8DV79+6t1ufOndtpjiOOiJ/L\nomuTk5PhayITExPVel9fX7U+b14cT4fqEipPyACQgEAGgAQEMgAkIJABIAGBDAAJ6LKeYb/61a/C\na++//361/uSTT1brP/vZzzrP/+1vf7tav/zyy6v1devWdZ4DDiVR527U5dzq9I26psfGxqr16Deh\nlFJ2797d6TWjo6PVen9/fzhH1AG9aNGi8DWRBQsWVOvz58+v1qOu7NZ9Rd3f03mAxoHkCRkAEhDI\nAJCAQAaABAQyACQgkAEggTmztPfnwb3h6H74yle+Uq3/9Kc/neE72T+nnXZatf7II4+Er1myZMmB\nup2DwcHRtnkIGBkZmdXfi6gzOuoCbnVGv/XWW9X6iy++WK0/9thj4VivvfZatb5p06ZqPeoKX7p0\naTjH6tWrq/WVK1dW65dddlk41plnntlp/qiTupRSxsfHq/XoPbb23u7amd3q2I7ydHh4eL9+Lzwh\nA0ACAhkAEhDIAJCAQAaABAQyACQgkAEgAYdLTNFMLG86++yzq/VPf/rT1fqGDRvCsX75y19W688/\n/3y1ftddd4VjffGLXwyvwcGktfyz68EPb7zxRjjW+vXrq/UnnniiWn/ppZfCsaLDJVatWlWtn3DC\nCdV6tBSrlFKeeuqpan1kZKRaP+mkk8Kx1q5dW61Hn33rcIloedMRR3R/xux68MSBXCrsCRkAEhDI\nAJCAQAaABAQyACQgkAEgAV3W++H1118Pr/385z/vNNZ5550XXvvjH/9YrQ8ODlbr0ebr0Wb4pZTy\n8ssvV+uPPvpotb5169ZwLDhUtDpn586dW61H3detruWoM3v58uXV+po1a8Kxzj333Go9+o1ZvHhx\ntd7q5P7JT35Srb/99tvVeutgjagrPPocW9/J6Ohotb5gwYJqfdeuXeFY8+fPr9aj772XTu795QkZ\nABIQyACQgEAGgAQEMgAkIJABIAFd1vuh1WkcdQJGnY5//vOfw7EWLlzY7cYCt912W3gt2jM38olP\nfGKKdwP5RR21pcR7Kkf7KQ8NDYVjnXrqqdV6tAf0WWedFY51yimnVOtHHnlktR51QG/bti2cI1qx\nEXWSR53cpZTS399frfeyN/TAwEC1vnPnzmq9tV/1+Ph4tR51bLfGmuo+156QASABgQwACQhkAEhA\nIANAAgIZABIQyACQgGVP++Gcc84Jr0VLoqKDH6J2/enUOvAiavGHQ0m0NGXevPpPXmspS3SYQLTE\nZ9WqVeFYxx9/fLUeHSCzaNGicKzoN2bHjh3V+rPPPlut33nnneEcv/3tb6v1s88+u1pvLd2MlmNF\nn/3k5GQ4VrTkLNLLgRBTXcLUC0/IAJCAQAaABAQyACQgkAEgAYEMAAnosp6iJUuWzNrcd9xxR7Ue\ndVO2XHnlldV6tOk9ZBZ17kbdufPnzw/Hiq4dddRR1frSpUvDsaIO6GiOVpd1dPDD5s2bq/W//vWv\n1fpzzz0XzhF1TV9wwQXV+umnnx6OFX0n0cqPd999Nxwr6kqPOs9bh4dEnfdjY2PVeutvZao8IQNA\nAgIZABIQyACQgEAGgAQEMgAkoMv6IPD0009X61/+8per9ag7sJRSjj322Gr95ptvrtYPZEchTEVr\n/+loH+LWayLRPsj9/f3VetS1W0opo6Oj1Xq0WiPqGi6llN27d1fr27Ztq9Y3bdpUrbc+k6uuuqpa\n/9jHPlatR53npcTd1Dt37qzWh4aGwrGiruno82r9Jkai7/1A7nHtCRkAEhDIAJCAQAaABAQyACQg\nkAEgAYEMAAlY9nQQWL9+fbXeSyv/9ddfX62feuqpnceCrKKlPFG9tZQluhYd7hAt7yklXkYYzdE6\nYOGNN96o1u+///5q/Z///Ge1fsIJJ4RznHPOOdX66tWrq/WJiYlwrOhgj2iZ2OTkZOexouVQAwMD\n4Vizsbwp4gkZABIQyACQgEAGgAQEMgAkIJABIAFd1olcd9111fqvf/3rTuN8/etfD69985vf7DQW\nZNVLZ3QvXdbRaobooIhWd3DrwISat956K7x21113Veu/+c1vqvXFixdX6xdffHE4x5o1a6r1FStW\nVOutLuuo+3zhwoXVetT9XEopu3btqtaj7zfqvm7p2qlfytQ7sz0hA0ACAhkAEhDIAJCAQAaABAQy\nACSgy3qGvffee+G1++67r1qPujmPPvroav2mm24K5+jr62vcHRwaunZTt7pjo87hqPu69X8s6vaN\n7nfLli3hWI8//ni1Ht3vKaecUq1fdtll4RznnXdetT44OFitR79VpcTvMdpnuvVbGXWyt7q8I9Fe\n2r105E+VJ2QASEAgA0ACAhkAEhDIAJCAQAaABHRZz7Crr746vNbat7bma1/7WrW+bNmyTuPAoSbq\nhI32R967d284VvSaRYsWdR6razf1U089FY61bdu2an3p0qXVetRNfe6554ZzRPtf7969u1qP9pgu\nJX7vO3bs6DxW1BkddVm39sWezn3Pp8oTMgAkIJABIAGBDAAJCGQASEAgA0ACAhkAErDs6QB58skn\nq/WHHnqo81if+tSnqvUbbrih81hwOIiWrERay2KiJT5DQ0PVenSARGusF154oVp/5JFHwrFGRkaq\n9UsvvbRaP+OMM6r1+fPnh3Ps3LmzWn/zzTer9dZ7X7JkSbUeLW9qfSfR4Rbj4+PVeuvQi+j99/f3\nV+utv62pLonyhAwACQhkAEhAIANAAgIZABIQyACQgC7rKYq6Jm+88cZqPeoCbIk2f+/r6+s8FhwO\nom7XycnJzmNF3bZRd27r//jzzz9frUerLx599NFwrOOPP75aX7duXbW+evXqaj3qWC4lPvhhYGCg\nWl+wYEE4VvR7FR3GEc1RStyBHX3v0WEUrfmjsXo5PGR/eUIGgAQEMgAkIJABIAGBDAAJCGQASECX\n9RTdcsst1fqDDz7YeazrrruuWrdnNRxYrX2To/2Z9+zZU62PjY2FYz3zzDPVetRN3dobOdqz+pJL\nLqnWo72kJyYmwjmi10SfSasDOZon6mJfunRpOFbUyb5t27ZqPdovu5S4Mzz67A/k6hZPyACQgEAG\ngAQEMgAkIJABIAGBDAAJCGQASMCypym66aabpm2sH/7wh9W6QyRgekTLm6JlPK1r0bKnkZGRcKwN\nGzZU69EhDieccEI41uWXX16tL1++vFqPDtZoLQkaGhqq1qPPsbWEKjqIJ1p21Poco+VN0efbsmLF\nik73NdUDJFo8IQNAAgIZABIQyACQgEAGgAQEMgAkoMs6kffee69ab218P12iDd5b3ae9bK4fiTow\nb7755s5jRaL30uqUnz9//rTNz8yJOmG71kuJ/26i/6/vvPNOONbWrVur9S1btlTrK1euDMeKupCj\nTuPo/9imTZvCOaLfnqj7et68OFIWL15crUfv/fXXXw/H2rx5c7UeHTpx2mmnhWO1OtlnmidkAEhA\nIANAAgIZABIQyACQgEAGgAR0WScS7ak6E66//vpq/bjjjgtf8+abb1brP/7xj6flnmZK63P/0pe+\nNIN3wnTZt29ftR51TLe6rKOxIlE3cylxB/b27dur9SVLloRjPfDAA9X6vffeW61Hqx+i7udS4vce\n7YvdGmvv3r3VetQt/vbbb4djRfOsWbOmWh8cHAzHWrRoUbU+GyssPCEDQAICGQASEMgAkIBABoAE\nBDIAJCCQASABy56m6Nprr63Wb7311hm+k6m55ZZbDvgcrY3nW4dY1HzhC18Ir1144YWdxrr44os7\n/XsOXtHSm9YBLtHSn+g1w8PD4VhnnXVWp/saHR0Nx4oOZXjppZeq9Z07d1br0UERpZSycOHCaj06\nWOboo48OxxoYGKjWly9fXq1HB96UUsqyZcuq9ZNPPrlaP/HEEzvfV7TsaTqXyP3/PCEDQAICGQAS\nEMgAkIBABoAEBDIAJDBnql1hPZqVSWfS7bffXq2Pj49P2xzPPvtstT6dhzt84xvfCK9FHY2Rq666\nKrwWdVomFrdaMq1GRkY6/15EnbCtTv9I1E0dzRF1M5dSyltvvVWtb9y4sVrftGlTONb7779frb/y\nyivV+rvvvluttzrMo4Myos/xpJNOCseKDniIuplbhztEvxcrV66s1luH5EQHeLS6qbsaHh7er8E8\nIQNAAgIZABIQyACQgEAGgAQEMgAkoMsaeqPLeob00mUdifZMj/aSbom6k1ud3FHn7sTERKc5Wq+J\nOqOj+vbt28M5os7s6D0ec8wx4VjRZx+9x1Y2Re896uTu6+sLx+ql874rXdYAcBARyACQgEAGgAQE\nMgAkIJABIAGBDAAJHPh+b4Ak9uzZ0/k10ZKoaKzWHL0sb4pES3yiwxJahzVExsbGqvXoM2nNEb0m\nmmNycjIcK7oWLStrHRQxS0t/qzwhA0ACAhkAEhDIAJCAQAaABAQyACSgyxqgIToUIerObXXtRt3U\n0RytQxGi1+zatavT3K2DNbre7/j4eDhWNE/0mlZndOvawcwTMgAkIJABIAGBDAAJCGQASEAgA0AC\nuqwBGrruddxLd3DUzdyaO9oDOupajvaZbt1vtPd2JOq+bonmb3V/d5Vpv+oWT8gAkIBABoAEBDIA\nJCCQASABgQwACQhkAEjAsieAGdJ1eVNr6U/0mnnz6j/rvcwRmYmlSocjT8gAkIBABoAEBDIAJCCQ\nASABgQwACcw5WDbdBoBDmSdkAEhAIANAAgIZABIQyACQgEAGgAQEMgAkIJABIAGBDAAJCGQASEAg\nA0ACAhkAEhDIAJCAQAaABAQyACQgkAEgAYEMAAkIZABIQCADQAICGQASEMgAkIBABoAEBDIAJCCQ\nASABgQwACQhkAEhAIANAAv8H9rTjCanvwGoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11342cb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_reconstructed_digits(X, outputs, \"./my_model_all_layers.ckpt\")\n",
    "save_fig(\"reconstruction_plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 150  # codings\n",
    "n_hidden3 = n_hidden1\n",
    "n_outputs = n_inputs\n",
    "\n",
    "learning_rate = 0.01\n",
    "l2_reg = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "activation = tf.nn.elu\n",
    "regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
    "initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "\n",
    "weights1_init = initializer([n_inputs, n_hidden1])\n",
    "weights2_init = initializer([n_hidden1, n_hidden2])\n",
    "\n",
    "weights1 = tf.Variable(weights1_init, dtype=tf.float32, name=\"weights1\")\n",
    "weights2 = tf.Variable(weights2_init, dtype=tf.float32, name=\"weights2\")\n",
    "weights3 = tf.transpose(weights2, name=\"weights3\")  # tied weights\n",
    "weights4 = tf.transpose(weights1, name=\"weights4\")  # tied weights\n",
    "\n",
    "biases1 = tf.Variable(tf.zeros(n_hidden1), name=\"biases1\")\n",
    "biases2 = tf.Variable(tf.zeros(n_hidden2), name=\"biases2\")\n",
    "biases3 = tf.Variable(tf.zeros(n_hidden3), name=\"biases3\")\n",
    "biases4 = tf.Variable(tf.zeros(n_outputs), name=\"biases4\")\n",
    "\n",
    "hidden1 = activation(tf.matmul(X, weights1) + biases1)\n",
    "hidden2 = activation(tf.matmul(hidden1, weights2) + biases2)\n",
    "hidden3 = activation(tf.matmul(hidden2, weights3) + biases3)\n",
    "outputs = tf.matmul(hidden3, weights4) + biases4\n",
    "\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))\n",
    "reg_loss = regularizer(weights1) + regularizer(weights2)\n",
    "loss = reconstruction_loss + reg_loss\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train MSE: 0.0153492\n",
      "1 Train MSE: 0.0155793\n",
      "2 Train MSE: 0.0157489\n",
      "3 Train MSE: 0.0175542\n",
      "4 Train MSE: 0.0173304\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        n_batches = mnist.train.num_examples // batch_size\n",
    "        for iteration in range(n_batches):\n",
    "            print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch})\n",
    "        loss_train = reconstruction_loss.eval(feed_dict={X: X_batch})\n",
    "        print(\"\\r{}\".format(epoch), \"Train MSE:\", loss_train)\n",
    "        saver.save(sess, \"./my_model_tying_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 150  # codings\n",
    "n_hidden3 = n_hidden1\n",
    "n_outputs = n_inputs\n",
    "\n",
    "learning_rate = 0.01\n",
    "l2_reg = 0.0001\n",
    "\n",
    "activation = tf.nn.elu\n",
    "regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
    "initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "\n",
    "weights1_init = initializer([n_inputs, n_hidden1])\n",
    "weights2_init = initializer([n_hidden1, n_hidden2])\n",
    "weights3_init = initializer([n_hidden2, n_hidden3])\n",
    "weights4_init = initializer([n_hidden3, n_outputs])\n",
    "\n",
    "weights1 = tf.Variable(weights1_init, dtype=tf.float32, name=\"weights1\")\n",
    "weights2 = tf.Variable(weights2_init, dtype=tf.float32, name=\"weights2\")\n",
    "weights3 = tf.Variable(weights3_init, dtype=tf.float32, name=\"weights3\")\n",
    "weights4 = tf.Variable(weights4_init, dtype=tf.float32, name=\"weights4\")\n",
    "\n",
    "biases1 = tf.Variable(tf.zeros(n_hidden1), name=\"biases1\")\n",
    "biases2 = tf.Variable(tf.zeros(n_hidden2), name=\"biases2\")\n",
    "biases3 = tf.Variable(tf.zeros(n_hidden3), name=\"biases3\")\n",
    "biases4 = tf.Variable(tf.zeros(n_outputs), name=\"biases4\")\n",
    "\n",
    "hidden1 = activation(tf.matmul(X, weights1) + biases1)\n",
    "hidden2 = activation(tf.matmul(hidden1, weights2) + biases2)\n",
    "hidden3 = activation(tf.matmul(hidden2, weights3) + biases3)\n",
    "outputs = tf.matmul(hidden3, weights4) + biases4\n",
    "\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs - X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "with tf.name_scope(\"phase1\"):\n",
    "    phase1_outputs = tf.matmul(hidden1, weights4) + biases4\n",
    "    phase1_reconstruction_loss = tf.reduce_mean(tf.square(phase1_outputs - X))\n",
    "    phase1_reg_loss = regularizer(weights1) + regularizer(weights4)\n",
    "    phase1_loss = phase1_reconstruction_loss + phase1_reg_loss\n",
    "    phase1_training_op = optimizer.minimize(phase1_loss)\n",
    "\n",
    "with tf.name_scope(\"phase2\"):\n",
    "    phase2_reconstruction_loss = tf.reduce_mean(tf.square(hidden3 - hidden1))\n",
    "    phase2_reg_loss = regularizer(weights2) + regularizer(weights3)\n",
    "    phase2_loss = phase2_reconstruction_loss + phase2_reg_loss\n",
    "    train_vars = [weights2, biases2, weights3, biases3]\n",
    "    phase2_training_op = optimizer.minimize(phase2_loss, var_list=train_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training phase #1\n",
      "0 Train MSE: 0.00755415\n",
      "1 Train MSE: 0.0080339\n",
      "2 Train MSE: 0.0077422\n",
      "3 Train MSE: 0.00810079\n",
      "Training phase #2\n",
      "0 Train MSE: 0.0879374\n",
      "1 Train MSE: 0.00523638\n",
      "2 Train MSE: 0.00248058\n",
      "3 Train MSE: 0.00209804\n",
      "Test MSE: 0.00975249\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_ops = [phase1_training_op, phase2_training_op]\n",
    "reconstruction_losses = [phase1_reconstruction_loss, phase2_reconstruction_loss]\n",
    "n_epochs = [4, 4]\n",
    "batch_sizes = [150, 150]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for phase in range(2):\n",
    "        print(\"Training phase #{}\".format(phase + 1))\n",
    "        for epoch in range(n_epochs[phase]):\n",
    "            n_batches = mnist.train.num_examples // batch_sizes[phase]\n",
    "            for iteration in range(n_batches):\n",
    "                print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n",
    "                sys.stdout.flush()\n",
    "                X_batch, y_batch = mnist.train.next_batch(batch_sizes[phase])\n",
    "                sess.run(training_ops[phase], feed_dict={X: X_batch})\n",
    "            loss_train = reconstruction_losses[phase].eval(feed_dict={X: X_batch})\n",
    "            print(\"\\r{}\".format(epoch), \"Train MSE:\", loss_train)\n",
    "            saver.save(sess, \"./my_model_one_at_a_time.ckpt\")\n",
    "    loss_test = reconstruction_loss.eval(feed_dict={X: mnist.test.images})\n",
    "    print(\"Test MSE:\", loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training phase #1\n",
      "0 Train MSE: 0.00793395\n",
      "19% Train MSE: 0.00798831\n",
      "2 Train MSE: 0.00767487\n",
      "3 Train MSE: 0.00792712\n",
      "Training phase #2\n",
      "0 Train MSE: 0.147047\n",
      "1 Train MSE: 0.00425239\n",
      "2 Train MSE: 0.00236566\n",
      "3 Train MSE: 0.00213308\n",
      "Test MSE: 0.00975909\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tvars' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1dadb75dcd50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test MSE:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtvars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtvars_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tvars' is not defined"
     ]
    }
   ],
   "source": [
    "training_ops = [phase1_training_op, phase2_training_op]\n",
    "reconstruction_losses = [phase1_reconstruction_loss, phase2_reconstruction_loss]\n",
    "n_epochs = [4, 4]\n",
    "batch_sizes = [150, 150]\n",
    "\n",
    "import numpy.random as rnd\n",
    "rnd.permutation(1)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for phase in range(2):\n",
    "        print(\"Training phase #{}\".format(phase + 1))\n",
    "        if phase == 1:\n",
    "            hidden1_cache = hidden1.eval(feed_dict={X: mnist.train.images})\n",
    "        for epoch in range(n_epochs[phase]):\n",
    "            n_batches = mnist.train.num_examples // batch_sizes[phase]\n",
    "            for iteration in range(n_batches):\n",
    "                print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n",
    "                sys.stdout.flush()\n",
    "                if phase == 1:\n",
    "                    indices = rnd.permutation(mnist.train.num_examples)\n",
    "                    hidden1_batch = hidden1_cache[indices[:batch_sizes[phase]]]\n",
    "                    feed_dict = {hidden1: hidden1_batch}\n",
    "                    sess.run(training_ops[phase], feed_dict=feed_dict)\n",
    "                else:\n",
    "                    X_batch, y_batch = mnist.train.next_batch(batch_sizes[phase])\n",
    "                    feed_dict = {X: X_batch}\n",
    "                    sess.run(training_ops[phase], feed_dict=feed_dict)\n",
    "            loss_train = reconstruction_losses[phase].eval(feed_dict=feed_dict)\n",
    "            print(\"\\r{}\".format(epoch), \"Train MSE:\", loss_train)\n",
    "            saver.save(sess, \"./my_model_cache_frozen.ckpt\")\n",
    "    loss_test = reconstruction_loss.eval(feed_dict={X: mnist.test.images})\n",
    "    print(\"Test MSE:\", loss_test)\n",
    "    \n",
    "    for var, val in zip(tvars, tvars_vals):\n",
    "        print(var.name, val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_one_at_a_time.ckpt\") \n",
    "    weights1_val = weights1.eval()\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plot_image(weights1_val.T[i])\n",
    "\n",
    "save_fig(\"extracted_features_plot\") \n",
    "plt.show()                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 150\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "l2_reg = 0.0005\n",
    "\n",
    "activation = tf.nn.elu\n",
    "regularizer = tf.contrib.layers.l2_regularizer(l2_reg)\n",
    "initializer = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs])\n",
    "y = tf.placeholder(tf.int32, shape=[None])\n",
    "\n",
    "weights1_init = initializer([n_inputs, n_hidden1])\n",
    "weights2_init = initializer([n_hidden1, n_hidden2])\n",
    "weights3_init = initializer([n_hidden2, n_hidden3])\n",
    "\n",
    "weights1 = tf.Variable(weights1_init, dtype=tf.float32, name=\"weights1\")\n",
    "weights2 = tf.Variable(weights2_init, dtype=tf.float32, name=\"weights2\")\n",
    "weights3 = tf.Variable(weights3_init, dtype=tf.float32, name=\"weights3\")\n",
    "\n",
    "biases1 = tf.Variable(tf.zeros(n_hidden1), name=\"biases1\")\n",
    "biases2 = tf.Variable(tf.zeros(n_hidden2), name=\"biases2\")\n",
    "biases3 = tf.Variable(tf.zeros(n_hidden3), name=\"biases3\")\n",
    "\n",
    "hidden1 = activation(tf.matmul(X, weights1) + biases1)\n",
    "hidden2 = activation(tf.matmul(hidden1, weights2) + biases2)\n",
    "logits = tf.matmul(hidden2, weights3) + biases3\n",
    "\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "reg_loss = regularizer(weights1) + regularizer(weights2) + regularizer(weights3)\n",
    "loss = cross_entropy + reg_loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "pretrain_saver = tf.train.Saver([weights1, weights2, biases1, biases2])\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 4\n",
    "batch_size = 150\n",
    "n_labeled_instances = 20000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        n_batches = n_labeled_instances // batch_size\n",
    "        for iteration in range(n_batches):\n",
    "            print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            indices = rnd.permutation(n_labeled_instances)[:batch_size]\n",
    "            X_batch, y_batch = mnist.train.images[indices], mnist.train.labels[indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        print(\"\\r{}\".format(epoch), \"Train accuracy:\", accuracy_val, end=\" \")\n",
    "        saver.save(sess, \"./my_model_supervised.ckpt\")\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
    "        print(\"Test accuracy:\", accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 4\n",
    "batch_size = 150\n",
    "n_labeled_instances = 20000\n",
    "\n",
    "#training_op = optimizer.minimize(loss, var_list=[weights3, biases3])  # Freeze layers 1 and 2 (optional)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    pretrain_saver.restore(sess, \"./my_model_cache_frozen.ckpt\")\n",
    "    for var, val in zip(tvars, tvars_vals):\n",
    "        print(var.name, val) \n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        n_batches = n_labeled_instances // batch_size\n",
    "        for iteration in range(n_batches):\n",
    "            print(\"\\r{}%\".format(100 * iteration // n_batches), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "            indices = rnd.permutation(n_labeled_instances)[:batch_size]\n",
    "            X_batch, y_batch = mnist.train.images[indices], mnist.train.labels[indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        print(\"\\r{}\".format(epoch), \"Train accuracy:\", accuracy_val, end=\"\\t\")\n",
    "        saver.save(sess, \"./my_model_supervised_pretrained.ckpt\")\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
    "        print(\"Test accuracy:\", accuracy_val)\n",
    "    tvars = tf.trainable_variables()\n",
    "    \n",
    "    tvars_vals = sess.run(tvars)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
